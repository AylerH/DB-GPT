# 创建
# 暂不实现
## 知识库-领域类型仅有一种normal可选

# 待实现
## 知识库对话命中定位解决

## 知识库-无法选择embedding模型

## 大模型-对话不可中断
要求可以终止；

**实现方案：**
1. 后端：添加 `/chat/cancel` API 端点，使用 request_id 跟踪请求
2. 前端：在生成时显示"停止"按钮
3. 相关代码：
   - `dbgpt_app/openapi/api_v2.py` - `/v2/chat/completions`
   - `dbgpt_core/.../apiserver/api.py` - `/v1/chat/completions`


## 文件上传-与结构化信息提取（先尝试工作流）
根据键值对类型提示词提取指定结构化信息。

## 模型管理
### 模型编辑与测试模型连通性
模型管理中要求可以编辑并测试模型连通性。
编辑模型应该能够看到当初创建模型时包含的信息并修改。
编辑模型返回的都是固定的内容，不是指定模型的。
数据库导入内容时应该要选择指定embeding模型。
编辑模型显示的模型信息不全；
添加新嵌入模型失败；

# 已实现
## 解决知识库-创建后名称和描述不可修改
以下要求可编辑修改
```
*知识库名称
输入名称
*描述
请输入描述
```

```
编辑页面是有了，但是报错请求 URL
http://127.0.0.1:5670/api/v2/serve/rag/spaces
请求方法
PUT
状态代码
405 Method Not Allowed
（1）更新知识库名称报错：

1 次请求
已传输348 B
请求 URL
http://127.0.0.1:5670/api/v2/serve/knowledge/spaces
请求方法
PUT
状态代码
{
    "success": false,
    "err_code": "400",
    "err_msg": "no space name named 图片pdf和透明文本层1",
    "data": null
}
（2）更新描述报错：http://127.0.0.1:5670/api/v2/serve/knowledge/spaces
请求方法
PUT
{
    "success": false,
    "err_code": "E0003",
    "err_msg": "1 validation error for SpaceServeRequest\nvector_type\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
    "data": null
}
pydantic_core._pydantic_core.ValidationError: 1 validation error for SpaceServeRequest

vector_type

  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]
```

**实现方案：**
1. 后端 API 已存在：`PUT /api/v2/serve/rag/spaces`
2. 服务层已实现：`service.update_space(request)`
3. 只需前端添加编辑入口即可

## rag成功
虽然embedding能连接上，但是它不在storage中。

## 对话成功
### 模型测试连接成功。但对话中报错
对话能用的时候embedidng用不了。embedding能用了对话又报错: 
模型测试连接成功。但对话中报错： File "/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py", line 409, in _simple_select

    raise Exception(

Exception: Cound not found worker instances for model name free:Qwen3-30B-A3B and worker type llm。请求 URL
http://127.0.0.1:5670/api/v1/chat/completions
请求方法
POST

原因：
```
当容器重启时，IP 地址可能会改变，但数据库中保存的是旧的 IP。系统从数据库加载模型时，会尝试使用旧的 host/port，导致冲突。

让我清除这个旧记录并重启：
```

## conf全部变量配置到.env
configs文件夹中所有文件的name = "${env:LLM_MODEL_NAME:-gpt-4o}"
provider = "${env:LLM_MODEL_PROVIDER:-proxy/openai}"
api_base = "${env:OPENAI_API_BASE:-https://api.openai.com/v1}"
api_key = "${env:OPENAI_API_KEY}"相关变量要求都可以从.env中配置，且环境变量名不同的根据文件名进行命名

## 知识库的es配置
### rag启用-增加es和知识库
要求前端增加知识库功能，可以上传文件，并按文件夹区分所属知识库；
embedding相关模型要求也可以通过openai兼容形式从.env中配置；
ELASTICSEARCH_URL=localhost
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_USERNAME=elastic
ELASTICSEARCH_PASSWORD=dbgpt，是不是可以把es配置到docker compose

报错：
```
[SERVER_ERROR]HTTPConnectionPool(host='localhost', port=8100): Max retries exceeded with url: /api/v1/embeddings (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f03b0355650>: Failed to establish a new connection: [Errno 111] Connection refused'))
```
### 不需要的
在左侧菜单栏添加知识库按钮，要求可以上传文件并rag。把左侧的知识库按钮去掉吧，因为应用管理里已经包含了。

## openai兼容模式的.env配置
api_key等的前端配置
改为可以自己输入openai兼容形式的url和api key

### 测试连通性；
点击测试连接没有任务反应，而且也没有编辑模型的按钮。
模型连通性测试应该加在图示所在页面。
.env中模型的也配置到storage；

测试连接http://127.0.0.1:5670/api/v2/serve/model/models/test报错：{
    "success": false,
    "err_code": "E000X",
    "err_msg": "Connection failed: 405 {\"detail\":\"Method Not Allowed\"}",
    "data": null
}

### 无用模型删不掉
模型停止不掉，编辑模型显示内容不全。Request error
model stop failed No worker instance found for the model bge-m3:latest worker type text2vec

```
http://127.0.0.1:5670/api/v2/serve/model/models/stop{
  "host": "172.25.0.4",
  "port": 5670,
  "model": "bge-m3:latest",
  "worker_type": "text2vec",
  "delete_after": true,
  "params": {}
}{
    "success": false,
    "err_code": "E000X",
    "err_msg": "model stop failed No worker instance found for the model bge-m3:latest worker type text2vec",
    "data": null
}
```